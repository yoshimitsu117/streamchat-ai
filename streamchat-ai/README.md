# ğŸ’¬ StreamChat AI

**Real-time LLM Chat Platform with Multi-Model Routing**

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![WebSocket](https://img.shields.io/badge/WebSocket-Real--time-010101?style=for-the-badge)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![OpenAI](https://img.shields.io/badge/Multi--Model-GPT%20%7C%20Gemini-412991?style=for-the-badge)

---

## ğŸ§  Overview

StreamChat AI is a **production-grade real-time chat platform** that supports streaming LLM responses via WebSockets and Server-Sent Events. It features **multi-model routing** (OpenAI GPT, Google Gemini), persistent conversation history, token-based rate limiting, and API key authentication.

Built for teams needing a **self-hosted, scalable chat backend** with full control over model selection, rate limits, and conversation management.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Client Layer                       â”‚
â”‚         WebSocket / SSE / REST API                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Application                   â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Auth         â”‚  â”‚ Rate Limiter  â”‚              â”‚
â”‚  â”‚ Middleware   â”‚  â”‚ (Token-based) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                 â”‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚        Chat Manager             â”‚              â”‚
â”‚  â”‚  (Session + Stream Control)     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                 â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚        Model Router             â”‚              â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚              â”‚
â”‚  â”‚  â”‚ OpenAI  â”‚  â”‚  Gemini  â”‚     â”‚              â”‚
â”‚  â”‚  â”‚ Client  â”‚  â”‚  Client  â”‚     â”‚              â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚    Conversation History         â”‚              â”‚
â”‚  â”‚    (SQLite Persistence)         â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

- **Real-time Streaming** â€” WebSocket and SSE support for token-by-token output
- **Multi-Model Router** â€” Switch between OpenAI GPT-4 and Google Gemini
- **Conversation History** â€” SQLite-backed persistent chat history
- **Rate Limiting** â€” Token-based rate limiting per API key
- **API Key Auth** â€” Bearer token authentication middleware
- **Session Management** â€” Multiple concurrent chat sessions
- **Async Architecture** â€” Fully async Python with FastAPI and asyncio
- **Docker Ready** â€” Production container deployment

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- OpenAI API key and/or Google Gemini API key

### 1. Clone & Install
```bash
git clone https://github.com/yoshimitsu117/streamchat-ai.git
cd streamchat-ai
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure
```bash
cp .env.example .env
# Add your API keys
```

### 3. Run
```bash
uvicorn app.main:app --reload --port 8003
```

### 4. Chat via REST
```bash
curl -X POST http://localhost:8003/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "message": "Explain quantum computing in simple terms",
    "model": "gpt-4o-mini",
    "session_id": "demo-session"
  }'
```

### 5. Chat via WebSocket
```python
import asyncio
import websockets

async def main():
    async with websockets.connect("ws://localhost:8003/ws/chat/demo-session") as ws:
        await ws.send('{"message": "Hello!", "model": "gpt-4o-mini"}')
        async for token in ws:
            print(token, end="", flush=True)

asyncio.run(main())
```

---

## ğŸ³ Docker
```bash
docker-compose up --build
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/chat` | Send a message (JSON response) |
| `POST` | `/api/v1/chat/stream` | Send a message (SSE stream) |
| `WS`   | `/ws/chat/{session_id}` | WebSocket chat connection |
| `GET`  | `/api/v1/sessions` | List active sessions |
| `GET`  | `/api/v1/sessions/{id}/history` | Get session history |
| `DELETE` | `/api/v1/sessions/{id}` | Delete a session |
| `GET`  | `/api/v1/models` | List available models |
| `GET`  | `/health` | Health check |

---

## ğŸ“ Project Structure

```
streamchat-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app + WebSocket endpoints
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ manager.py       # Chat session management
â”‚   â”‚   â”œâ”€â”€ streaming.py     # SSE & WebSocket streaming
â”‚   â”‚   â””â”€â”€ history.py       # Conversation history (SQLite)
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ router.py        # Multi-model router
â”‚   â”‚   â”œâ”€â”€ openai_client.py # OpenAI provider
â”‚   â”‚   â”œâ”€â”€ gemini_client.py # Google Gemini provider
â”‚   â”‚   â””â”€â”€ base.py          # Abstract LLM provider
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ rate_limiter.py   # Token-based rate limiting
â”‚       â””â”€â”€ auth.py           # API key authentication
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_chat.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ‘¤ Author

**Siddharth** â€” AI Engineer  
Building production-grade AI systems, not just demos.

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=flat&logo=linkedin)](https://linkedin.com/in/yoshimitsu117)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=flat&logo=github)](https://github.com/yoshimitsu117)
